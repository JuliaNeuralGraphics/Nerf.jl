var documenterSearchIndex = {"docs":
[{"location":"renderer/#Renderer","page":"Renderer","title":"Renderer","text":"","category":"section"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Nerf.jl provides a simple renderer which can be used for visualizing trainer NeRF model.","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"using LinearAlgebra\nusing Nerf: Renderer, Camera","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"To create a renderer, pass camera that uses dataset's intrinsics, trainer's bounding box and cone:","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"camera = Camera(MMatrix{3, 4, Float32}(I), dataset.intrinsics)\nrenderer = Renderer(Backend, camera, trainer.bbox, trainer.cone)","category":"page"},{"location":"renderer/#Tiled-renderer","page":"Renderer","title":"Tiled renderer","text":"","category":"section"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"To allow rendering high-resolution frames, Renderer automatically switches to a tiled mode, once the number of pixels in the frames exceeds tile_size parameter.","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Controlling the size of the tile can be done with tile_size keyword when creating Renderer:","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"renderer = Renderer(\n    Backend, camera, trainer.bbox, trainer.cone;\n    tile_size=512 * 512) # 512x512 pixels in each tile.","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Then, set the position of the camera (here we randomly select a pose from the dataset):","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"pose_idx = clamp(round(Int, rand() * length(dataset)), 1, length(dataset))\nNerf.set_projection!(camera, Nerf.get_pose(dataset, pose_idx)...)","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"And render whole frame in one go:","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Nerf.render!(renderer, trainer.occupancy, trainer.bbox) do points, directions\n    model(points, directions)\nend","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Nerf.render! accepts as first argument a function that will return RGBA colors evaluated at each point & direction in  points & directions.","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Thus the rendered does not know anything about the NeRF model and can be used for generic ray marching visualizations.","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"Renderer writes everything to its internal buffer. To save the rendering result, convert the buffer to an image and save it:","category":"page"},{"location":"renderer/","page":"Renderer","title":"Renderer","text":"rgba_image = to_image(renderer.buffer)\nrgb_image = RGB.(rgba_image)\nsave(\"image.png\", rgb_image)","category":"page"},{"location":"trainer/#Trainer","page":"Trainer","title":"Trainer","text":"","category":"section"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"Nerf.jl trainer accepts dataset which will be used for training and a generic NeRF model.","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"using Nerf\nusing Nerf: Backend, Dataset, BasicModel, BasicField, Trainer","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"Create dataset directly on the Backend:","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"config_file = joinpath(pkgdir(Nerf), \"data\", \"raccoon_sofa2\", \"transforms.json\")\ndataset = Dataset(Backend; config_file)","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"Create a NeRF model, which in this case is a model from Instant-NGP paper:","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"model = BasicModel(BasicField(Backend))","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"Create trainer by providing model, dataset and a maximum number of rays in each training batch:","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"trainer = Trainer(model, dataset; n_rays=1024)","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"After this, training can be done in a loop by calling Nerf.step! on a trainer:","category":"page"},{"location":"trainer/","page":"Trainer","title":"Trainer","text":"for i in 1:20_000\n    loss = Nerf.step!(trainer)\n    @show i, loss\nend","category":"page"},{"location":"custom/#Creating-Custom-Dataset","page":"Creating Custom Dataset","title":"Creating Custom Dataset","text":"","category":"section"},{"location":"custom/","page":"Creating Custom Dataset","title":"Creating Custom Dataset","text":"By default Nerf.jl and NerfGUI.jl comes with its own Raccoon dataset.","category":"page"},{"location":"custom/","page":"Creating Custom Dataset","title":"Creating Custom Dataset","text":"However, it is easy to create custom ones.","category":"page"},{"location":"custom/#Steps","page":"Creating Custom Dataset","title":"Steps","text":"","category":"section"},{"location":"custom/","page":"Creating Custom Dataset","title":"Creating Custom Dataset","text":"Nerf.jl uses same input format as instant-ngp.","category":"page"},{"location":"custom/","page":"Creating Custom Dataset","title":"Creating Custom Dataset","text":"Take a short clip of an object you want to reconstruct.\nUsing colmap2nerf.py script reconstruct camera poses  via COLMAP.  Below is an example command:\n~$ python3 colmap2nerf.py --video_in=input.mp4 --video_fps=2 --run_colmap --aabb_scale=4\nIt will slice video into frames, run COLMAP camera pose reconstruction  and save the results in transforms.json file along with  images in images/ directory.\nMake sure paths in transform.json point correctly to the images.\nOpen transforms.json in NerfGUI.jl application by pasting its path  in the datasets window.","category":"page"},{"location":"#Nerf.jl","page":"Home","title":"Nerf.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Real-time Neural Radiance Fields in pure Julia.","category":"page"},{"location":"#Requirements","page":"Home","title":"Requirements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia 1.9 or above.\nAMD or Nvidia GPU (check AMDGPU.jl or CUDA.jl for respective device support).\nAt least 4-6 GB of VRAM.","category":"page"},{"location":"#GPU-backend","page":"Home","title":"GPU backend","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Use Nerf.set_backend!(name) to specify which GPU backend to use, which takes a String with backend name:","category":"page"},{"location":"","page":"Home","title":"Home","text":"AMD GPU: Nerf.set_backend!(\"AMDGPU\");\nNvidia: Nerf.set_backend!(\"CUDA\").","category":"page"},{"location":"","page":"Home","title":"Home","text":"And then restart your Julia session if returns true.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternatively, if you cloned Nerf.jl repo, you can create LocalPreferences.toml file and specify backend in it with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"[Nerf]\nbackend = \"AMDGPU\" # or \"CUDA\"","category":"page"},{"location":"#Quickstart-(NerfGUI.jl)","page":"Home","title":"Quickstart (NerfGUI.jl)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For standalone application check NerfGUI.jl package, which provides OpenGL application for real-time interaction.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Clone git clone https://github.com/JuliaNeuralGraphics/NerfGUI.jl.git.\nStart Julia repl julia --project=. --threads=auto.\nInstantiate project with ]up command.\nSelect GPU backend as described above.\nLaunch application:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using NerfGUI\n\njulia> NerfGUI.main()","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Instant Neural Graphics Primitives with a Multiresolution Hash Encoding:  https://nvlabs.github.io/instant-ngp/.","category":"page"}]
}
